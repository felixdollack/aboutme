---
title: Augmenting interoceptive awareness with off-the-shelf sensors using visuo-haptic emotional stimulus
date: 2022-11-30T00:00:00

# Schedule page publish date (NOT publication's date).
publishDate: '2022-11-30T00:00:00Z'

# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
authors:
 - F. Dollack
 - Hoda Aitbaali
 - Marisabel Cuberos-Balda
 - Luc Gommane
 - Diego Felipe Paez-Granados
 - Monica Perusquía-Hernández
 - Jose Salazar
 - David Gomez Jauregui

# Publication type.
# Legend:
# 0 = Uncategorized
# 1 = Conference paper
# 2 = Journal article
# 3 = Manuscript
# 4 = Report
# 5 = Book
# 6 = Book section
publication_types: ["1"]

# Publication name and optional abbreviated version.
publication: "In *Avances en Interacción Humano-Computadora*."
publication_short: "In *Avances en Interacción Humano-Computadora*"

# Abstract.
abstract: "Wearable sensing technologies allow us to monitor and track a wealth of information about bodily states. Tracking applications rely on abstract numerical or graphical visualizations to make this information accessible to us. However, these visualizations can be hard to interpret, and even be harmful to already vulnerable groups. Hence, we propose to give feedback in the form of an enhanced heart rate interoception and an embodied artificial agent. This method relies on the person’s inherent understanding of their own body. It is a subtle and more natural way to gauge the meaning of off-the-shelf sensors’ feedback. A wearable pet prototype that presents emotion through visuo-haptic feedback is evaluated in a match and a mismatch group. Participants in both groups answered self-report and perceived affect of the interoceptive feedback without significant differences. However, the groups’ perceived closeness to the pet differed significantly."

# Summary. An optional shortened abstract.
summary: ""

# Digital Object Identifier (DOI)
doi: "10.47756/aihc.y7i1.120"

# Is this a featured publication? (true/false)
featured: false

# Tags (optional).
#   Set `tags: []` for no tags, or use the form `tags: ["A Tag", "Another Tag"]` for one or more tags.
tags: []

# Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects: ["deep-learning"]` references
#   `content/project/deep-learning/index.md`.
#   Otherwise, set `projects: []`.
projects: []

# Links (optional).
url_pdf: ""
url_preprint: ""
url_code: ""
url_dataset: ""
url_project: ""
url_slides: ""
url_video: ""
url_poster: ""
url_source: ""

# Custom links (optional).
#   Uncomment line below to enable. For multiple links, use the form `[{...}, {...}, {...}]`.
#links: [{name = "Custom Link", url = "http://example.org"}]

# Does this page contain LaTeX math? (true/false)
math: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
image:
  # Caption (optional)
  caption: "Image credit: [**Unsplash**](https://unsplash.com/photos/pLCdAaMFLTE)"

  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  focal_point: ""

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: []

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ''
---
